# Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
# Use of this file is governed by the BSD 3-clause license that
# can be found in the LICENSE.txt file in the project root.
#

require_relative "../ll1_analyzer"
require_relative "../interval_set"
require_relative "../token"

class ATN
  INVALID_ALT_NUMBER = 0

  attr_accessor(:grammar_type, :max_token_type, :states, :decision_to_state,
                :rule_to_start_state, :rule_to_stop_state, :mode_name_to_start_state,
                :rule_to_token_type, :lexer_actions, :mode_to_state_state)

  def initialize(grammar_type, max_token_type)

    # Used for runtime deserialization of ATNs from strings
    # The type of the ATN.
    @grammar_type = grammar_type
    # The maximum value for any symbol recognized by a transition in the ATN.
    @max_token_type = max_token_type
    @states = []
    # Each subrule/rule is a decision point and we must track them so we
    # can go back later and build DFA predictors for them.  This includes
    # all the rules, subrules, optional blocks, ()+, ()* etc...
    @decision_to_state = []
    # Maps from rule index to starting state number.
    @rule_to_start_state = []
    # Maps from rule index to stop state number.
    @rule_to_stop_state = nil
    # this is a Hash {} object.
    @mode_name_to_start_state = {}
    # For lexer ATNs, this maps the rule index to the resulting token type.
    # For parser ATNs, this maps the rule index to the generated bypass token
    # type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}
    # deserialization option was specified; otherwise, this is {@code null}
    #/
    @rule_to_token_type = nil
    # For lexer ATNs, this is an array of {@link LexerAction} objects which may
    # be referenced by action transitions in the ATN
    @lexer_actions = nil
    @mode_to_state_state = []
  end

  # Compute the set of valid tokens that can occur starting in state {@code s}.
  # If {@code ctx} is null, the set of tokens will not include what can follow
  # the rule surrounding {@code s}. In other words, the set will be
  # restricted to tokens reachable staying within {@code s}'s rule
  #/
  def next_tokens_in_context(s, ctx)
    anal = LL1Analyzer.new(self)
    anal.look(s, nil, ctx)
  end

  # Compute the set of valid tokens that can occur starting in {@code s} and
  # staying in same rule. {@link Token//EPSILON} is in set if we reach end of
  # rule
  #/
  def next_tokens_no_context(s)
    return s.next_token_within_rule unless s.next_token_within_rule.nil?
    s.next_token_within_rule = next_tokens_in_context(s, nil)
    s.next_token_within_rule.read_only = true
    s.next_token_within_rule
  end

  def next_tokens(s, ctx = nil)
    return next_tokens_no_context(s) if ctx == nil
    next_tokens_in_context(s, ctx)
  end

  def add_state(state)
    unless state.nil?
      state.atn = self
      state.state_number = @states.size
    end
    @states << state
  end

  def remove_state(state)
    @states[state.state_number] = nil # just free mem, don't shift states in list
  end

  def define_decision_state(s)
    @decision_to_state << s
    s.decision = @decision_to_state.size - 1
    s.decision
  end

  def get_decision_state(decision)
    return nil if @decision_to_state.size == 0
    @decision_to_state[decision]
  end

  # Computes the set of input symbols which could follow ATN state number
  # {@code stateNumber} in the specified full {@code context}. This method
  # considers the complete parser context, but does not evaluate semantic
  # predicates (i.e. all predicates encountered during the calculation are
  # assumed true). If a path in the ATN exists from the starting state to the
  # {@link RuleStopState} of the outermost context without matching any
  # symbols, {@link Token//EOF} is added to the returned set.
  #
  # <p>If {@code context} is {@code null}, it is treated as
  # {@link ParserRuleContext//EMPTY}.</p>
  #
  # @param stateNumber the ATN state number
  # @param ctx the full parse context
  #
  # @return {IntervalSet} The set of potentially valid input symbols which could follow the
  # specified state in the specified context.
  #
  # @throws IllegalArgumentException if the ATN does not contain a state with
  # number {@code stateNumber}
  #/
  def get_expected_tokens(state_number, ctx)
    raise(Exception, "Invalid state number.") if state_number < 0 or state_number >= @states.size
    s = @states[state_number]
    following = next_tokens(s)
    return following unless following.contains?(Token::EPSILON)
    expected = IntervalSet.new()
    expected.add_set(following)
    expected.remove_one(Token::EPSILON)
    while not ctx.nil? and ctx.invoking_state >= 0 and following.contains?(Token::EPSILON)
      invoking_state = @states[ctx.invoking_state]
      rt = invoking_state.transitions[0]
      following = next_tokens(rt.follow_state)
      expected.add_set(following)
      expected.remove_one(Token::EPSILON)
      ctc = ctx.parent_ctx
    end
    expected.add_one(Token::EOF) if following.contains?(Token::EPSILON)
    expected
  end
end
